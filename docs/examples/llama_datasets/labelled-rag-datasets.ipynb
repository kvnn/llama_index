{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a481b689-d363-40a9-a8a4-7d8c6a3a67bd",
   "metadata": {},
   "source": [
    "# Benchmarking RAG Pipelines With A `LabelledRagDatatset`\n",
    "\n",
    "The `LabelledRagDataset` is meant to be used for evaluating any given RAG pipeline, for which there could be several configurations (i.e. choosing the `LLM`, values for the `similarity_top_k`, `chunk_size`, and others). We've likened this abstract to traditional machine learning datastets, where `X` features are meant to predict a ground-truth label `y`. In this case, we use the `query` as well as the retrieved `contexts` as the \"features\" and the answer to the query, called `reference_answer` as the ground-truth label.\n",
    "\n",
    "And of course, such datasets are comprised of observations or examples. In the case of `LabelledRagDataset`, these are made up with a set of `LabelledRagDataExample`'s.\n",
    "\n",
    "In this notebook, we will show how one can construct a `LabelledRagDataset` from scratch. Please note that the alternative to this would be to simply download a community supplied `LabelledRagDataset` from `llama-hub` in order to evaluate/benchmark your own RAG pipeline on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d14822-2779-4da9-bfb7-201f361b8eb1",
   "metadata": {},
   "source": [
    "### The `LabelledRagDataExample` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017a52c-e61b-4172-b996-c7d7ce56c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llama_dataset import (\n",
    "    LabelledRagDataExample,\n",
    "    CreatedByType,\n",
    "    CreatedBy,\n",
    ")\n",
    "\n",
    "# constructing a LabelledRagDataExample\n",
    "query = \"This is a test query, is it not?\"\n",
    "query_by = CreatedBy(type=CreatedByType.AI, model_name=\"gpt-4\")\n",
    "reference_answer = \"Yes it is.\"\n",
    "reference_answer_by = CreatedBy(type=CreatedByType.HUMAN)\n",
    "reference_contexts = [\"This is a sample context\"]\n",
    "\n",
    "rag_example = LabelledRagDataExample(\n",
    "    query=query,\n",
    "    query_by=query_by,\n",
    "    reference_contexts=reference_contexts,\n",
    "    reference_answer=reference_answer,\n",
    "    reference_answer_by=reference_answer_by,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f295953f-bbe1-4cc2-8a60-1eb75678d57e",
   "metadata": {},
   "source": [
    "The `LabelledRagDataExample` is a Pydantic `Model` and so, going from `json` or `dict` (and vice-versa) is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa5b37-4453-49c4-8527-9a5c772dd436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\": \"This is a test query, is it not?\", \"query_by\": {\"model_name\": \"gpt-4\", \"type\": \"ai\"}, \"reference_contexts\": [\"This is a sample context\"], \"reference_answer\": \"Yes it is.\", \"reference_answer_by\": {\"model_name\": \"\", \"type\": \"human\"}}\n"
     ]
    }
   ],
   "source": [
    "print(rag_example.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86da0f2-c11b-41b1-bfe7-8c5be9f51a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelledRagDataExample(query='This is a test query, is it not?', query_by=CreatedBy(model_name='gpt-4', type=<CreatedByType.AI: 'ai'>), reference_contexts=['This is a sample context'], reference_answer='Yes it is.', reference_answer_by=CreatedBy(model_name='', type=<CreatedByType.HUMAN: 'human'>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelledRagDataExample.parse_raw(rag_example.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23231be-6cc1-49f7-81e9-b2721d1ac836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'This is a test query, is it not?',\n",
       " 'query_by': {'model_name': 'gpt-4', 'type': <CreatedByType.AI: 'ai'>},\n",
       " 'reference_contexts': ['This is a sample context'],\n",
       " 'reference_answer': 'Yes it is.',\n",
       " 'reference_answer_by': {'model_name': '',\n",
       "  'type': <CreatedByType.HUMAN: 'human'>}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_example.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3040e95-d459-4193-8c45-5238001f1da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelledRagDataExample(query='This is a test query, is it not?', query_by=CreatedBy(model_name='gpt-4', type=<CreatedByType.AI: 'ai'>), reference_contexts=['This is a sample context'], reference_answer='Yes it is.', reference_answer_by=CreatedBy(model_name='', type=<CreatedByType.HUMAN: 'human'>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelledRagDataExample.parse_obj(rag_example.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97213dd9-c828-4781-af09-c690d9234103",
   "metadata": {},
   "source": [
    "Let's create a second example, so we can have a (slightly) more interesting `LabelledRagDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1986f16f-3f80-4c22-89a0-4d9fa1475d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"This is a test query, is it so?\"\n",
    "reference_answer = \"I think yes, it is.\"\n",
    "reference_contexts = [\"This is a second sample context\"]\n",
    "\n",
    "rag_example_2 = LabelledRagDataExample(\n",
    "    query=query,\n",
    "    query_by=query_by,\n",
    "    reference_contexts=reference_contexts,\n",
    "    reference_answer=reference_answer,\n",
    "    reference_answer_by=reference_answer_by,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709422c5-8d1d-462a-bfe8-2eabc73c077f",
   "metadata": {},
   "source": [
    "### The `LabelledRagDataset` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2750320c-ae60-455b-a79c-e8774bf4fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llama_dataset.rag import LabelledRagDataset\n",
    "\n",
    "rag_dataset = LabelledRagDataset(examples=[rag_example, rag_example_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2812220-f176-49bd-af7c-9a01c3a2dd2a",
   "metadata": {},
   "source": [
    "There exists a convienience method to view the dataset as a `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1511ddc-c0ed-4aeb-9ff8-76b090d54dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a test query, is it not?</td>\n",
       "      <td>[This is a sample context]</td>\n",
       "      <td>Yes it is.</td>\n",
       "      <td>human</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a test query, is it so?</td>\n",
       "      <td>[This is a second sample context]</td>\n",
       "      <td>I think yes, it is.</td>\n",
       "      <td>human</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              query                 reference_contexts  \\\n",
       "0  This is a test query, is it not?         [This is a sample context]   \n",
       "1   This is a test query, is it so?  [This is a second sample context]   \n",
       "\n",
       "      reference_answer reference_answer_by    query_by  \n",
       "0           Yes it is.               human  ai (gpt-4)  \n",
       "1  I think yes, it is.               human  ai (gpt-4)  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f541811-043f-4065-9905-0734173f329f",
   "metadata": {},
   "source": [
    "#### Serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63716f0-7723-4f21-9f80-703b257f8b48",
   "metadata": {},
   "source": [
    "To persist and load the dataset to and from disk, there are the `save_json` and `from_json` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a2781-b4c4-49e6-8245-e2381aacc833",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset.save_json(\"rag_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400b2c3-5b49-40c2-897b-ac3819beb87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_rag_dataset = LabelledRagDataset.from_json(\"rag_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e13eb-120a-434c-a04b-5c0b9fdcd60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a test query, is it not?</td>\n",
       "      <td>[This is a sample context]</td>\n",
       "      <td>Yes it is.</td>\n",
       "      <td>human</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a test query, is it so?</td>\n",
       "      <td>[This is a second sample context]</td>\n",
       "      <td>I think yes, it is.</td>\n",
       "      <td>human</td>\n",
       "      <td>ai (gpt-4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              query                 reference_contexts  \\\n",
       "0  This is a test query, is it not?         [This is a sample context]   \n",
       "1   This is a test query, is it so?  [This is a second sample context]   \n",
       "\n",
       "      reference_answer reference_answer_by    query_by  \n",
       "0           Yes it is.               human  ai (gpt-4)  \n",
       "1  I think yes, it is.               human  ai (gpt-4)  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_rag_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166f98e8-239a-4007-8754-5a9b4edb41a4",
   "metadata": {},
   "source": [
    "### Predicting and Evaluation\n",
    "\n",
    "For this section, we'll first create a `LabelledRagDataset` using a synthetic generator. Ultimately, we will use GPT-4 to produce both the `query` and `reference_answer` for the synthetic `LabelledRagDataExample`'s.\n",
    "\n",
    "NOTE: if one has queries, reference answers, and contexts over a text corpus, then it is not necessary to use data synthesis to be able to predict and subsequently evaluate said predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cc6fc1-376c-44ca-8370-a0849e96265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133efdb3-cfdb-49db-8b9a-76338b907500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "# Load documents and build index\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"data/paul_graham_essay_truncated.txt\"]\n",
    ").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c6567-b420-4d5c-a022-dfb4889da795",
   "metadata": {},
   "source": [
    "The `RagDatasetGenerator` can be build over a set of documents to generate `LabelledRagDataExample`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f930d75-7a93-4d4c-a647-5f8eeefe37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate questions against chunks\n",
    "from llama_index.llama_dataset.generator import RagDatasetGenerator\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index import ServiceContext\n",
    "\n",
    "# set context for llm provider\n",
    "gpt_35_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)\n",
    ")\n",
    "\n",
    "# instantiate a DatasetGenerator\n",
    "dataset_generator = RagDatasetGenerator.from_documents(\n",
    "    documents,\n",
    "    service_context=gpt_35_context,\n",
    "    num_questions_per_chunk=2,  # set the number of questions per nodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02137f2-023c-4312-a484-f0a79eb65ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.evaluation import DatasetGenerator, QueryResponseDataset\n",
    "\n",
    "# dataset_generator = DatasetGenerator.from_documents(\n",
    "#     documents,\n",
    "#     service_context=gpt_35_context,\n",
    "#     num_questions_per_chunk=25,\n",
    "# )\n",
    "\n",
    "# qrd = QueryResponseDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf592778-a914-4bbf-a88b-3bbc715d70d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_generator.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c3dc4-3109-411c-87eb-2d130ff757a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there are 2 nodes, there should be a total of 4 questions\n",
    "rag_dataset = dataset_generator.generate_dataset_from_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052a43e-3a7a-4f0f-9f0c-7542ffbb64d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did the availability of microcomputers cha...</td>\n",
       "      <td>[What I Worked On\\n\\nFebruary 2021\\n\\nBefore c...</td>\n",
       "      <td>The availability of microcomputers changed the...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What factors influenced Paul Graham's decision...</td>\n",
       "      <td>[What I Worked On\\n\\nFebruary 2021\\n\\nBefore c...</td>\n",
       "      <td>Two factors influenced Paul Graham's decision ...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How did the novel \"The Moon is a Harsh Mistres...</td>\n",
       "      <td>[I couldn't have put this into words when I wa...</td>\n",
       "      <td>The novel \"The Moon is a Harsh Mistress\" and t...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why did the author choose to learn Lisp as a p...</td>\n",
       "      <td>[I couldn't have put this into words when I wa...</td>\n",
       "      <td>The author chose to learn Lisp as a programmin...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  How did the availability of microcomputers cha...   \n",
       "1  What factors influenced Paul Graham's decision...   \n",
       "2  How did the novel \"The Moon is a Harsh Mistres...   \n",
       "3  Why did the author choose to learn Lisp as a p...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [What I Worked On\\n\\nFebruary 2021\\n\\nBefore c...   \n",
       "1  [What I Worked On\\n\\nFebruary 2021\\n\\nBefore c...   \n",
       "2  [I couldn't have put this into words when I wa...   \n",
       "3  [I couldn't have put this into words when I wa...   \n",
       "\n",
       "                                    reference_answer reference_answer_by  \\\n",
       "0  The availability of microcomputers changed the...  ai (gpt-3.5-turbo)   \n",
       "1  Two factors influenced Paul Graham's decision ...  ai (gpt-3.5-turbo)   \n",
       "2  The novel \"The Moon is a Harsh Mistress\" and t...  ai (gpt-3.5-turbo)   \n",
       "3  The author chose to learn Lisp as a programmin...  ai (gpt-3.5-turbo)   \n",
       "\n",
       "             query_by  \n",
       "0  ai (gpt-3.5-turbo)  \n",
       "1  ai (gpt-3.5-turbo)  \n",
       "2  ai (gpt-3.5-turbo)  \n",
       "3  ai (gpt-3.5-turbo)  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86d33ec-61b7-49a9-ab29-050a82088e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset.save_json(\"rag_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aae5d0-086d-43cd-89e2-51119329a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_ragdataset = LabelledRagDataset.from_json(\"rag_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f600662d-d2f6-45fa-8296-db668d7a65cc",
   "metadata": {},
   "source": [
    "#### Predicting\n",
    "\n",
    "Stepping back for a second to paint the situation before moving on to making actual predictions. Recall that the point of the `LabelledRagDataset` is to benchmark any given RAG pipeline that is built over the same source documents (in this case, the `paul_graham_essay_truncated.txt`).\n",
    "\n",
    "So, let's emulate that situation now by creating a simple RAG pipeline (i.e., index, then query engine) over the same source text data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24af81-a4ad-4d6b-ae47-4ecc538a3b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"data/paul_graham_essay_truncated.txt\"]\n",
    ").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54c32a-faf4-4642-9541-b1dc12a90e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26ea016-ef6b-4870-97e7-1e0ac11825f4",
   "metadata": {},
   "source": [
    "A `LabelledRagDataset` has a method call `make_predictions_with` that takes as input a `QueryEngine` to produce predictions (i.e. generate responses to the queries). Specifically, it returns a `RagPredictionDataset` that is comprised of a set of `RagExamplePrediction`'s, which store the generated response as well as the context that was retrieved by the retrievor of the RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447472f-1f39-46e8-917b-e7e370f5ddd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "prediction_dataset = await rag_dataset.amake_predictions_with(\n",
    "    query_engine=query_engine, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54563bcb-aa22-46b5-905c-0ffca32e18b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "prediction_dataset = rag_dataset.make_predictions_with(\n",
    "    query_engine=query_engine, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2d585-0453-47ac-b6be-8fc8010a8bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRST 100 CHARS of RESPONSE:\n",
      "The availability of microcomputers changed the way people could interact with computers and engage i...\n",
      "\n",
      "=================\n",
      "TOP 0 RETRIEVAL:\n",
      "What I Worked On\n",
      "\n",
      "February 2021\n",
      "\n",
      "Before college the two main things I worked on, outside of school, ...\n",
      "\n",
      "=================\n",
      "TOP 1 RETRIEVAL:\n",
      "I couldn't have put this into words when I was 18. All I knew at the time was that I kept taking phi...\n",
      "\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "# taking a peak at a single RagExamplePrediction\n",
    "pred = prediction_dataset.predictions[0]\n",
    "\n",
    "print(f\"FIRST 100 CHARS of RESPONSE:\\n{pred.response[:100]}...\")\n",
    "print(\"\\n=================\")\n",
    "for ix, c in enumerate(pred.contexts):\n",
    "    print(f\"TOP {ix} RETRIEVAL:\\n{c[:100]}...\\n\")\n",
    "    print(\"=================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea390b-4526-4bad-84c8-850df720271a",
   "metadata": {},
   "source": [
    "Just as with `LabelledRagDataset`'s, you can store into and upload from a json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878afe82-35ec-43df-98bf-769636d20674",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dataset.save_json(\"prediction_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5461ba-8284-4a93-86c1-8473d5428bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llama_dataset import RagPredictionDataset\n",
    "\n",
    "reloaded_predictions = RagPredictionDataset.from_json(\n",
    "    \"prediction_dataset.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b121c1c8-1d21-4442-96dc-5af8195e3443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The availability of microcomputers changed the...</td>\n",
       "      <td>[What I Worked On\\n\\nFebruary 2021\\n\\nBefore c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paul Graham's decision to switch from studying...</td>\n",
       "      <td>[I couldn't have put this into words when I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The novel \"The Moon is a Harsh Mistress\" and t...</td>\n",
       "      <td>[I couldn't have put this into words when I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The author chose to learn Lisp as a programmin...</td>\n",
       "      <td>[I couldn't have put this into words when I wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response  \\\n",
       "0  The availability of microcomputers changed the...   \n",
       "1  Paul Graham's decision to switch from studying...   \n",
       "2  The novel \"The Moon is a Harsh Mistress\" and t...   \n",
       "3  The author chose to learn Lisp as a programmin...   \n",
       "\n",
       "                                            contexts  \n",
       "0  [What I Worked On\\n\\nFebruary 2021\\n\\nBefore c...  \n",
       "1  [I couldn't have put this into words when I wa...  \n",
       "2  [I couldn't have put this into words when I wa...  \n",
       "3  [I couldn't have put this into words when I wa...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_predictions.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_3.10",
   "language": "python",
   "name": "llama_index_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
